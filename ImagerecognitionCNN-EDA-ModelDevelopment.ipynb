{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1fbb227",
   "metadata": {},
   "source": [
    "Welcome to my EDA, prior to making a Convolutional Neural Network (CNN). CNN are commonly used for classification or binary problems. \n",
    "We will use this exploration to determine how we are going to build our model, by testing accuracy and build. Then when we are happy we will create the model in a py file, and make it ready to deploy onto a flask based API.\n",
    "\n",
    "In this first section we will explore and process our inputs by doing the following:\n",
    "1) Download the dataset and visualise the images ( CIFAR-10 )\n",
    "2) Change the label to one hot encodings ( Create a binary classification columns)\n",
    "3) Scale the image pixel values to take between 0 and 1 ( So our image can be processed by a numerically based model\n",
    "\n",
    "Details about the CIFAR-10 dataset:\n",
    "1) Images ( 32*32 pixels) (This is the scale of the images)\n",
    "2) labels 10 possible identifier labels ( This can be amended dependant on what you are analysing. In this case we have ten different types of animals we can identify)\n",
    "3) Dataset size is  60k images, (We will split this into 50k training and 10k testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc502c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets begin by importing our dataset.\n",
    "from keras.datasets imports cifar10\n",
    "# The dataset has already been split at source:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92a6378",
   "metadata": {},
   "source": [
    "However, if your receive images that have not yet been split you could use the following:\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.17, random_state=50)\n",
    "\n",
    "Test size is 0.17 as 50k(training size) of 60k images is 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to check our imported data has split correctly. Lets run the following:\n",
    "print('x_train shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e745cba",
   "metadata": {},
   "source": [
    "The result above tells us that our training data is made up of 50k images, which are 32 pixels in height, 32 pixels in width and 3 pixels in depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa056046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see what the shape of the label array is.\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7c3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also investigate what an image looks like, when it is broken down into pixels\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fcc480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above we can see the image result is almost a tensore or array of numbers.\n",
    "# However, this does not tell use very much.\n",
    "# Lets use matplotlib.pyplot to visualise this in a better way\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26362a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is very hard to make out what the image is due to pixelation.\n",
    "# Lets see what the training data classifies this image as\n",
    "\n",
    "print('the label is:', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259fc86",
   "metadata": {},
   "source": [
    "If we are building a predictor which identifies is we will experience above or below median we can set only used 2 labels, 1(above) or 0(below), this is because there was only two possible outputs. Furthermore it is important to consider that many numerical problems, will have better approaches that forcing a Neural Network. Such as, Random Forests, Decision Trees, Regression.\n",
    "\n",
    "However, image input recognition is a multi classing problem, where there is 10 possible outputs in this case. As a result our outputs possibility will be 10 neurons or classifications.\n",
    "\n",
    "In order to solve the multi class issue and respect that the CNN needs numerical factors. We will initiate a one hot encoding feature\n",
    "One hot encoding, will take the approach that if the image belongs to first class, all relevant rows of this column will be assigned a number of 1, the others 0\n",
    "\n",
    "If the image belongs to the second class, all relevant rows of this second columns will be set to 1 and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05283757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets initiate our one hot encoding using keras\n",
    "import keras\n",
    "y_train_one_hot = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_one_hot = keras.utils.to_categorial(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0cd33e",
   "metadata": {},
   "source": [
    "We need to talk about what just happened above. The number 10, symbolizes the 10 different possible classifications an image can receive.\n",
    "However, be aware that columns are counted as 0-9 in python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4053643c",
   "metadata": {},
   "source": [
    "At this point we have set our class classification as one hot encoding so we can produce results from our CNN.\n",
    "Now we want to process our image(x)\n",
    "\n",
    "A common approach to this, is to allow the numbers to be between 0 and 1, this will aid in the training of our neural network\n",
    "Since our pixel values already take the values between 0 and 255 (32x32), we simply divide by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd3963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4bc9c5",
   "metadata": {},
   "source": [
    "Checkpoint! Up until this point, we have:\n",
    "1) Downloaded the dataset and visualised the images using matplotlib\n",
    "2) Changed the y labels to one hot encodings. This makes them numerical and able to pass into our CNN\n",
    "3) scaled the image pixel value to take between 0 and 1. By dividing by the pixel size we have in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a7ea6",
   "metadata": {},
   "source": [
    "BUILDING AND TRAINING OUR CONVOLUTIONAL NEURAL NETWORK\n",
    "\n",
    "We have arrived at the point where we will define our model.\n",
    "\n",
    "The CNN architecture, which we will be building is as follows:\n",
    "\n",
    "1) we input our image\n",
    "\n",
    "2) we have our first Conv layer ( filter = 3x3, stride = 1,Depth = 32)\n",
    "\n",
    "3) we have our second Conv layer ( filter = 3x3, stride = 1,Depth = 32)\n",
    "\n",
    "4) we have a Max pool Layer ( filter = 2x2, stride = 2)\n",
    "\n",
    "5) we have a dropout layer (probability:0.25)\n",
    "\n",
    "6) we have our third Conv layer ( filter = 3x3, stride = 1,Depth = 64)\n",
    "\n",
    "7) we have our fourth Conv layer ( filter = 3x3, stride = 1,Depth = 64)\n",
    "\n",
    "8) we have a second Max pool Layer ( filter = 2x2, stride = 2)\n",
    "\n",
    "9) we have a second dropout layer (probability:0.25)\n",
    "\n",
    "10) we then have a FC Layer ( Neurons = 512)\n",
    "\n",
    "11) we have a third dropout layer (probability:0.5)\n",
    "\n",
    "12) we then have a second FC Layer ( Neurons =10)\n",
    "\n",
    "13) we then have a softmax Layer\n",
    "\n",
    "14) finally we have our classification results\n",
    "\n",
    "What is cool about this, is that we can amend and play with the model set up ourselves, to see if we can improve our results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c3fbba",
   "metadata": {},
   "source": [
    "The softmax layer (13), transforms the output of the layer into probability distributions, which is what we want for our classification problem\n",
    "\n",
    "What we have not specified in the model breakdown above is padding. For now, we will zero pad our layer. So output width and height is the same as the input width and height.\n",
    "\n",
    "This is called same padding, for a 3x3 filter, to achieve the same width and height, we have pad with a border of 1\n",
    "\n",
    "Finally we will use the ReLU activation for all our layers, except the last(which uses a softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78d777",
   "metadata": {},
   "source": [
    "To code the above breakdown into a functional model, we will use the Keras sequential model. However, since there is many layers in our model, we will do this as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf3374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8341d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next we will call an 'empty' sequential model\n",
    "model =  Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now the process, is to add a layer by layer to this empty model one at a time:\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32,32,3)))  # first layer, we did not specify stride, as this is default as 1, we specify if we want it to be different\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))   # we do not need to put input layer twice, since it can infer from previous input\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())    # At this point neurons are like  acube, we need to flatten them into one row using this function\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87357c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above we have manually input and created our model. We can now proceed to start filling in the best numbers\n",
    "# We will compile the model with the settings below:\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',           # adam is a sgd, with a few modifications so it trains better\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9377919",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can start training our model\n",
    "## If you notice we set up our validation split at 0.2. This is a shortcut that means we did not need to split our dataset up at the beginning,\n",
    "## instead we specify how much of our dataset will be used as a validation set.\n",
    "\n",
    "Classifier = model.fit(x_train, y_train_one_hot,\n",
    "                 batch_size=32, epochs=5,\n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79212d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have completed our model training, we can visualize the model training and validation loss over the number of epochs\n",
    "\n",
    "plt.plot(Classifier.history['loss'])\n",
    "plt.plot(Classifier.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89539ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets also have a look at the accuracy of what we created:\n",
    "\n",
    "plt.plot(Classifier.history['accuracy'])\n",
    "plt.plot(Classifier.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93acba04",
   "metadata": {},
   "source": [
    "At this point we can see the valuation accuracy is a lot lower than the test accuracy. This could be due to underfitting, or the have created our model. At this point we should investigate:\n",
    "\n",
    "1) hyper parameters\n",
    "2) number of epochs\n",
    "3) batch size\n",
    "\n",
    "Once we are happy we can then run our test set to see how well it performs on unseen data. (Note: as this is a demonstration of how to create such a model. At this point in time I have not spent much time tweaking it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets evaluate how the model does on the test data.\n",
    "model.evaluate(x_test, y_test_one_hot)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df878bd7",
   "metadata": {},
   "source": [
    "Not bad, we have an accuracy of 77%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea8cbc",
   "metadata": {},
   "source": [
    "\n",
    "If you are planning to stay in the Jupyter notebook you can use the following to save your model. However, in a more professional setting it is less likely that you will keep them as such. Nonetheless:\n",
    "\n",
    "We can now save our trained model, since it took so long to train by using the following code:\n",
    "\n",
    "model.save('my_cifar10_model.h5')\n",
    "\n",
    "if you want to access this model again in the future, we can use this line of code:\n",
    "\n",
    "from keras.models import load_model\n",
    "model= load_model('my_cifar10_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3108ca",
   "metadata": {},
   "source": [
    "Again, this part, assumes you will test your model in a jupyter notebook setting:\n",
    "\n",
    "TESTING OUR MODEL\n",
    "\n",
    "WE CAN IMPORT A IMAGE INTO OUR DIRECTORY\n",
    "THEN WE CAN IMPORT IT USING THE FOLLOWING CODE:\n",
    "MY_IMAGE = PLT.IMREAD(\"CAT.JPG\")\n",
    "\n",
    "WE THEN NEED TO RESIZE THE IMAGE, WE CAN DO THIS MANUALLY OR, \"IMPORT SCIKIT-IMAGE\" INSIDE THE ANAZONDA NAVIGATOR\n",
    "ONCE WE HAVE COMPLETED THAT, GO BACK TO JUPYTER NOTEBOOK AND START USING THE NEEDED FUNCTIONS:\n",
    "\n",
    "FROM SKIMAGE.TRANSFORM IMPORT RESIZE\n",
    "MY_IMAGE_RESIZED =  RESIZE(MY_IMAGE, (32,32,3))\n",
    "\n",
    "\n",
    "WE CAN VISUALISE OUR IMAGE TO TEST IT WORKED USING:\n",
    "#/ IMG = PLT.IMSHOW(MY_IMAGE_RESIZED)\n",
    "\n",
    "THEN WE CAN VIEW WHAT OUR TRAINED MODEL WOULD OUTPUT BASED ON THEIS PICTURE:\n",
    "IMPORT NUMPY AS NP\n",
    "PROBABILITIES = MODEL.PREDICT(NP.ARRACY([MY_IMAGE_RESIZED,]))\n",
    "\n",
    "WE CAN THEN VIEW IT RUNNING THE CODE:\n",
    "PROBABILITIES\n",
    "\n",
    "THE PROBABILITIES ARE OUTPUT IN ORDER FROM 0-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ddd8c8",
   "metadata": {},
   "source": [
    "##### Next steps\n",
    "\n",
    "Once you are happy with your data exploration and the model accuracy. The next step is creating the model in a .py file. Then being able to deploy it onto a development server using Flask. You will find the remaining files in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5af9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
